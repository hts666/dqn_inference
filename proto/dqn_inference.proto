syntax = "proto3";

package dqn_inference;
option go_package = "github.com/hts666/dqn_inference;dqn_inference";
// 每个 Task 的信息
message TaskInfo {
  int32 task_id = 1;
  float cpu_demand = 2;
  float memory_demand = 3;
  float gpu_demand = 4;
  // 你若有 arrival_time 或其他属性，也可加入
}

// 每个 Node 的信息
message NodeInfo {
  int32 node_id = 1;
  float cpuUsage = 2;
  float memoryUsage = 3;
  float gpuUsage = 4;
  float cpuRem = 5;
  float memoryRem = 6;
  float gpuRem = 7;
}

// 用于批量调度的请求
message BatchInferenceRequest {
  repeated NodeInfo nodes = 1;   // 所有节点
  repeated TaskInfo tasks = 2;   // 当前要调度的一批任务
}

// 批量调度的回复
// 包含对每个 task_id 的分配结果: node_id = -1 表示分配失败
message BatchInferenceReply {
  repeated int32 task_ids = 1;   // 与 tasks 对应的 ID
  repeated int32 node_ids = 2;   // 分配到的节点: -1 表示无可用节点
}

// DQNService 定义
service DQNService {
  // 一次性处理一批任务
  rpc PredictBatch (BatchInferenceRequest) returns (BatchInferenceReply);
}
